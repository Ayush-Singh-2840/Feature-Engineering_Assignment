{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "raw",
      "source": "1.What is a Parameter?\n- A parameter is a variable in a machine learning model that is learned from the training data. Parameters are internal to the model and are adjusted to minimize the error between the predicted and actual outcomes.\n\n2.What is Correlation?\n- Correlation measures the strength and direction of the linear relationship between two variables. It is usually expressed as a correlation coefficient (ranging from -1 to 1), where:\n-   1 indicates a perfect positive linear relationship,\n-  -1 indicates a perfect negative linear relationship,\n-  0 indicates no linear relationship.\n\n\nQuestion13.What Does Negative Correlation Mean?\n- Negative correlation means that as one variable increases, the other decreases. The correlation coefficient for a negative correlation is between -1 and 0.\n\n3.Define Machine Learning. What Are the Main Components in Machine Learning?\n- Machine Learning is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. The main components in machine learning are:\nData: The input used for training.\nModel: The mathematical representation of the learning process.\nAlgorithm: The procedure used to train the model.\nObjective Function: The function used to evaluate the performance of the model.\nOptimization: The process of finding the best parameters for the model.\nEvaluation: Assessing the model's performance using metrics.\n\n\n4.How Does Loss Value Help in Determining Whether the Model Is Good or Not?\n- The loss value quantifies the difference between the predicted values by the model and the actual values. A lower loss value indicates better model performance. The goal in training is to minimize this loss.\n\n5.What Are Continuous and Categorical Variables?\n-Continuous variables can take any value within a range (e.g., height, weight).\n-Categorical variables have a finite set of distinct categories or groups (e.g., gender, color).\n\n6.How Do We Handle Categorical Variables in Machine Learning? What Are the Common Techniques?\n-Categorical variables are handled using techniques such as:\n- One-Hot Encoding: Converts categories into binary columns.\n- Label Encoding: Assigns each category a unique integer.\n- Target Encoding: Uses the mean of the target variable for each category.\n\n7.What Do You Mean by Training and Testing a Dataset?\n-Training a dataset means using it to fit a machine learning model, while testing refers to using a separate dataset to evaluate the model's performance.\n\n8.What is sklearn.preprocessing?\n-sklearn.preprocessing is a module in scikit-learn that provides functions and classes to transform data before training a model, such as scaling, encoding, and normalizing.\n\n9.What is a Test Set?\n-A test set is a subset of data used to assess the performance of a trained model. It is not used during the training phase.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#10.How Do We Split Data for Model Fitting (Training and Testing) in Python?\n\n#- In Python, data splitting is commonly done using train_test_split from sklearn.model_selection. Example:\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "raw",
      "source": "#How Do You Approach a Machine Learning Problem?\n\nDefine the problem.\nCollect and prepare data.\nPerform Exploratory Data Analysis (EDA).\nFeature Engineering.\nSelect a model.\nTrain the model.\nEvaluate the model.\nTune the model.\nDeploy the model.\n    \n11.Why Do We Perform EDA Before Fitting a Model to the Data?\n- EDA helps understand the data distribution, relationships, and anomalies, which can inform model selection, feature engineering, and preprocessing steps.\n\n#Question No.12 is same as Question No.2",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#14.How Can You Find Correlation Between Variables in Python?\n#- You can find correlation using pandas or numpy. Example with pandas:\nimport pandas as pd\ncorrelation_matrix = df.corr()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "raw",
      "source": "15.What is Causation? Explain Difference Between Correlation and Causation With an Example.\n- Causation implies that one event causes another. Correlation indicates a relationship between two variables, but not necessarily causation. Example: Ice cream sales and drowning incidents may be correlated (both increase in summer), but buying ice cream doesn't cause drowning.\n\n16.What is an Optimizer? What Are Different Types of Optimizers?\n- An optimizer is an algorithm that adjusts the model's parameters to minimize the loss function. Common optimizers include:\nGradient Descent: Basic optimization method.\nStochastic Gradient Descent (SGD): Updates parameters using a single data point at a time.\nAdam: Combines momentum and adaptive learning rates.\n\n17.What is sklearn.linear_model?\n- sklearn.linear_model is a module in scikit-learn that provides linear models like Linear Regression, Logistic Regression, and Ridge.\n\n18.What Does model.fit() Do? What Arguments Must Be Given?\n- model.fit() trains the model on the given data. Arguments include:\nX: Feature matrix.\ny: Target variable.\n\n\n19.What Does model.predict() Do? What Arguments Must Be Given?\n- model.predict() makes predictions on new data. Argument:\nX: Feature matrix for which predictions are required.\n\n21.What is Feature Scaling? How Does It Help in Machine Learning?\nFeature scaling standardizes the range of features so that each feature contributes equally to the model, which is especially important for models sensitive to feature magnitudes.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#22.How Do We Perform Scaling in Python?\n# -Scaling is performed using StandardScaler or MinMaxScaler from sklearn.preprocessing. Example:\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "raw",
      "source": "2Explain Data Encoding\nData encoding converts categorical variables into a format suitable for machine learning algorithms. Techniques include one-hot encoding, label encoding, and ordinal encoding.\n",
      "metadata": {}
    }
  ]
}